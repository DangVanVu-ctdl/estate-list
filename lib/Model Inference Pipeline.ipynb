{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.1\n",
    "!pip install pandas==1.4.3\n",
    "!pip install matplotlib==3.3.2\n",
    "!pip install seaborn==0.11.0\n",
    "!pip install joblib==1.1.0\n",
    "!pip install nltk==3.7\n",
    "!pip install wordcloud==1.8.2.2\n",
    "!pip install scikit_learn==1.0.2\n",
    "!pip install scipy==1.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. [Loading the Data:](#Loading-the-Data:)\n",
    "\n",
    "II. [Helper functions to prepare the data:](#Helper-functions-to-prepare-the-data:)\n",
    "\n",
    "III. [Test Inference:](#Test-Inference:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time \n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average propery area (feature cleaning)\n",
    "def avg_property_area(x):\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\") \n",
    "    x = numbers.findall(x)\n",
    "    if len(x) == 1:\n",
    "        return np.float(x[0])\n",
    "    elif len(x) == 2:\n",
    "        return (np.float(x[0])+np.float(x[1]))/2\n",
    "    else:\n",
    "        return -99\n",
    "    \n",
    "# Outlier treatment\n",
    "def clip_outliers(df,col):\n",
    "    q_l = df[col].quantile(0.25)\n",
    "    q_h = df[col].quantile(0.95)\n",
    "    df[col] = df[col].clip(lower = q_l, upper = q_h)\n",
    "    return df    \n",
    "\n",
    "# Text cleaning\n",
    "# Preprocessing the text data\n",
    "REPLACE_BY_SPACE_RE = re.compile(\"[/(){}\\[\\]\\|@,;!]\")\n",
    "BAD_SYMBOLS_RE = re.compile(\"[^0-9a-z #+_]\")\n",
    "STOPWORDS_nlp = set(stopwords.words('english'))\n",
    "\n",
    "#Custom Stoplist\n",
    "stoplist = [\"i\",\"project\",\"living\",\"home\",'apartment',\"pune\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"you're\",\"you've\",\"you'll\",\"you'd\",\"your\",\n",
    "            \"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"she's\",\"her\",\"hers\",\"herself\",\"it\",\n",
    "            \"it's\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"that'll\",\n",
    "            \"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\n",
    "            \"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\n",
    "            \"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\n",
    "            \"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"all\",\"any\",\n",
    "            \"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\n",
    "            \"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"don't\",\"should\",\"should've\",\"now\",\"d\",\"ll\",\"m\",\"o\",\"re\",\"ve\",\"y\",\"ain\",\n",
    "            \"aren\",\"couldn\",\"didn\",\"doesn\",\"hadn\",\"hasn\",\n",
    "            \"haven\",\"isn\",\"ma\",\"mightn\",\"mustn\",\"needn\",\"shan\",\"shan't\",\n",
    "            \"shouldn\",\"wasn\",\"weren\",\"won\",\"rt\",\"rt\",\"qt\",\"for\",\n",
    "            \"the\",\"with\",\"in\",\"of\",\"and\",\"its\",\"it\",\"this\",\"i\",\"have\",\"has\",\"would\",\"could\",\"you\",\"a\",\"an\",\n",
    "            \"be\",\"am\",\"can\",\"edushopper\",\"will\",\"to\",\"on\",\"is\",\"by\",\"ive\",\"im\",\"your\",\"we\",\"are\",\"at\",\"as\",\"any\",\"ebay\",\"thank\",\"hello\",\"know\",\n",
    "            \"need\",\"want\",\"look\",\"hi\",\"sorry\",\"http\", \"https\",\"body\",\"dear\",\"hello\",\"hi\",\"thanks\",\"sir\",\"tomorrow\",\"sent\",\"send\",\"see\",\"there\",\"welcome\",\"what\",\"well\",\"us\"]\n",
    "\n",
    "STOPWORDS_nlp.update(stoplist)\n",
    "\n",
    "# Function to preprocess the text\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\d+\",\" \") # removing digits\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #removing mentions and urls\n",
    "    text = text.lower() # lowercase text\n",
    "    text =  re.sub('[0-9]+', '', text)\n",
    "    text = REPLACE_BY_SPACE_RE.sub(\" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub(\" \", text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS_nlp]) # delete stopwors from text\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Pos counter\n",
    "def pos_counter(x,pos):\n",
    "    \"\"\"\n",
    "    Returns the count for the given parts of speech tag\n",
    "    \n",
    "    NN - Noun\n",
    "    VB - Verb\n",
    "    JJ - Adjective\n",
    "    RB - Adverb\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(x.lower())\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS_nlp]\n",
    "    text = nltk.Text(tokens)\n",
    "    tags = nltk.pos_tag(text)\n",
    "    counts = Counter(tag for word,tag in tags)\n",
    "    return counts[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9cbdddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\DANG\n",
      "[nltk_data]     VU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Extracting State and Country separately from the Location Column\n",
    "    df['City'] = df['Location'].apply(lambda x: x.split(',')[0].lower().strip())\n",
    "    df['State'] = df['Location'].apply(lambda x: x.split(',')[1].lower().strip())\n",
    "    df['Country'] = df['Location'].apply(lambda x: x.split(',')[2].lower().strip())\n",
    "    \n",
    "    # Regex to match the numbers and create a separate column\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\") \n",
    "    df['Property Type Cleaned'] = df['Propert Type'].apply(lambda x: numbers.findall(x)[0] \n",
    "                                                           if len(numbers.findall(x)) > 0 else 0)\n",
    "    \n",
    "    # Cleaning the text columns\n",
    "    df['Sub-Area Cleaned'] = df['Sub-Area'].apply(lambda x: x.lower().strip())\n",
    "    df['Company Name Cleaned'] = df['Company Name'].apply(lambda x: x.lower().strip())\n",
    "    df['TownShip Name/ Society Name Cleaned'] = df['TownShip Name/ Society Name'].apply(lambda x: x.lower().strip())\n",
    "    df['Description Cleaned'] = df['Description'].apply(lambda x: x.lower().strip())\n",
    "    \n",
    "    \n",
    "    # Cleaning and encoding Binary Features\n",
    "    df['ClubHouse Cleaned'] = (df['ClubHouse'].apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['School / University in Township Cleaned'] = (df['School / University in Township ']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Hospital in TownShip Cleaned'] = (df['Hospital in TownShip']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Mall in TownShip Cleaned'] = (df['Mall in TownShip']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Park / Jogging track Cleaned'] = (df['Park / Jogging track']\n",
    "                                                         .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Swimming Pool Cleaned'] = (df['Swimming Pool']\n",
    "                                                     .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0}))\n",
    "    df['Gym Cleaned'] = (df['Gym']\n",
    "                                 .apply(lambda x: x.lower().strip()).map({'yes':1, 'no':0})) \n",
    "    \n",
    "    \n",
    "\n",
    "    # Cleaning numerical columns\n",
    "    numbers = re.compile(r\"[-+]?(\\d*\\.\\d+|\\d+)\")     \n",
    "    df['Property Area in Sq. Ft. Cleaned'] = df['Property Area in Sq. Ft.'].apply(lambda x: avg_property_area(str(x)))\n",
    "#     df['Price in lakhs Cleaned'] = (df['Price in lakhs'].apply(lambda x: np.float(numbers.findall(str(x))[0]) \n",
    "#                                                                if len(numbers.findall(str(x)))>0 else np.nan ))\n",
    "    \n",
    "    # Selecting the requried columns\n",
    "    features = df.columns.tolist()[18:]\n",
    "    df1 = df[features]\n",
    "    df_final = df1.dropna()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # outlier treatment\n",
    "    # Treating outliers in the numeric columns\n",
    "    cols_to_treat = ['Property Area in Sq. Ft. Cleaned']\n",
    "    \n",
    "    for col in cols_to_treat:\n",
    "        df = clip_outliers(df,col)\n",
    "    \n",
    "    # creating the price by sub-area feature\n",
    "    fileName = 'model/sub_area_price_map.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        sub_area_price_map = pickle.load(f)    \n",
    "    df['Price by sub-area'] =  df['Sub-Area Cleaned'].map(sub_area_price_map)\n",
    "    \n",
    "    # Adding the amenitites score feature\n",
    "    amenities_col = ['ClubHouse Cleaned',\n",
    "                     'School / University in Township Cleaned',\n",
    "                     'Hospital in TownShip Cleaned',\n",
    "                     'Mall in TownShip Cleaned',\n",
    "                     'Park / Jogging track Cleaned',\n",
    "                     'Swimming Pool Cleaned',\n",
    "                     'Gym Cleaned']\n",
    "    temp = df[amenities_col]\n",
    "    temp['Amenities score'] = temp.sum(axis=1)\n",
    "    df['Amenities score'] = temp['Amenities score']\n",
    "    \n",
    "    # creating the price by amenities score feature\n",
    "    fileName = 'model/amenities_score_price_map.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        amenities_score_price_map = pickle.load(f)  \n",
    "        \n",
    "    df['Price by Amenities score'] =  df['Amenities score'].map(amenities_score_price_map)\n",
    "    \n",
    "    # cleaning the description column and creating pos features\n",
    "    df[\"Description Cleaned\"] =  df[\"Description Cleaned\"].astype(str).apply(text_prepare)\n",
    "    df['Noun_Counts'] = df['Description Cleaned'].apply(lambda x: pos_counter(x,'NN'))\n",
    "    df['Verb_Counts'] = df['Description Cleaned'].apply(lambda x: (pos_counter(x,'VB')+pos_counter(x,'RB')))\n",
    "    df['Adjective_Counts'] = df['Description Cleaned'].apply(lambda x: pos_counter(x,'JJ'))\n",
    "    \n",
    "    # Ngram features\n",
    "    fileName = 'model/count_vectorizer.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        cv_object = pickle.load(f)\n",
    "    \n",
    "    X = cv_object.transform(df['Description Cleaned'])\n",
    "    df_ngram = pd.DataFrame(X.toarray(),columns=cv_object.get_feature_names())\n",
    "     \n",
    "    # Adding this to the main dataframe\n",
    "    df_final = pd.concat([df.reset_index(drop=True),df_ngram.reset_index(drop=True)],axis=1)\n",
    "    \n",
    "    # selecting the final model ready features\n",
    "    fileName = 'model/raw_features_mapping.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        feature_mapping = pickle.load(f)   \n",
    "        \n",
    "    fileName = 'model/features.pkl'\n",
    "    with open(fileName,'rb') as f:\n",
    "        feature_list = pickle.load(f)           \n",
    "    \n",
    "    # Removing price column as it is not available in test data\n",
    "    feature_list.remove('Price_in_lakhs')\n",
    "\n",
    "    df_final = df_final.rename(columns=feature_mapping)\n",
    "    df_final = df_final[feature_list]\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([Contents:](#Contents:))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Location</th>\n",
       "      <th>Sub-Area</th>\n",
       "      <th>Propert Type</th>\n",
       "      <th>Property Area in Sq. Ft.</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>TownShip Name/ Society Name</th>\n",
       "      <th>Total TownShip Area in Acres</th>\n",
       "      <th>ClubHouse</th>\n",
       "      <th>School / University in Township</th>\n",
       "      <th>Hospital in TownShip</th>\n",
       "      <th>Mall in TownShip</th>\n",
       "      <th>Park / Jogging track</th>\n",
       "      <th>Swimming Pool</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>1 BHK</td>\n",
       "      <td>492</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Shapoorji Paloonji comunity located in the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>774</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha Township located near the lonavala hill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>3 BHK</td>\n",
       "      <td>889</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha Society is suitable for all aged group ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>3 BHK Grand</td>\n",
       "      <td>1018</td>\n",
       "      <td>Shapoorji Paloonji</td>\n",
       "      <td>Vanaha</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vanaha township are offering 3BHK grand prpoer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>Mahalunge</td>\n",
       "      <td>2BHK</td>\n",
       "      <td>743</td>\n",
       "      <td>Godrej Properties</td>\n",
       "      <td>Godrej Hills retreat</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The area is a hub of prestigious schools like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr. No.                  Location   Sub-Area Propert Type  \\\n",
       "0        1  Pune, Maharashtra, India    Bavdhan        1 BHK   \n",
       "1        2  Pune, Maharashtra, India    Bavdhan        2 BHK   \n",
       "2        3  Pune, Maharashtra, India    Bavdhan        3 BHK   \n",
       "3        4  Pune, Maharashtra, India    Bavdhan  3 BHK Grand   \n",
       "4        5  Pune, Maharashtra, India  Mahalunge         2BHK   \n",
       "\n",
       "  Property Area in Sq. Ft.        Company Name TownShip Name/ Society Name  \\\n",
       "0                      492  Shapoorji Paloonji                     Vanaha    \n",
       "1                      774  Shapoorji Paloonji                     Vanaha    \n",
       "2                      889  Shapoorji Paloonji                     Vanaha    \n",
       "3                     1018  Shapoorji Paloonji                     Vanaha    \n",
       "4                      743   Godrej Properties        Godrej Hills retreat   \n",
       "\n",
       "   Total TownShip Area in Acres ClubHouse School / University in Township   \\\n",
       "0                        1000.0       Yes                              Yes   \n",
       "1                        1000.0       Yes                              Yes   \n",
       "2                        1000.0       Yes                              Yes   \n",
       "3                        1000.0       Yes                              Yes   \n",
       "4                         100.0       Yes                              Yes   \n",
       "\n",
       "  Hospital in TownShip Mall in TownShip Park / Jogging track Swimming Pool  \\\n",
       "0                  Yes              Yes                  Yes           Yes   \n",
       "1                  Yes              Yes                  Yes           Yes   \n",
       "2                  Yes              Yes                  Yes           Yes   \n",
       "3                  Yes              Yes                  Yes           Yes   \n",
       "4                  Yes              Yes                  Yes           Yes   \n",
       "\n",
       "   Gym                                        Description  \n",
       "0  Yes  Shapoorji Paloonji comunity located in the sub...  \n",
       "1  Yes  Vanaha Township located near the lonavala hill...  \n",
       "2  Yes  Vanaha Society is suitable for all aged group ...  \n",
       "3  Yes  Vanaha township are offering 3BHK grand prpoer...  \n",
       "4  Yes  The area is a hub of prestigious schools like ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "data= pd.read_excel('data/Pune Real Estate Data.xlsx')\n",
    "data = data.drop(['Price in Millions','Price in lakhs'],axis=1)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocess = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Property Type Cleaned</th>\n",
       "      <th>Sub-Area Cleaned</th>\n",
       "      <th>Company Name Cleaned</th>\n",
       "      <th>TownShip Name/ Society Name Cleaned</th>\n",
       "      <th>Description Cleaned</th>\n",
       "      <th>ClubHouse Cleaned</th>\n",
       "      <th>School / University in Township Cleaned</th>\n",
       "      <th>Hospital in TownShip Cleaned</th>\n",
       "      <th>Mall in TownShip Cleaned</th>\n",
       "      <th>Park / Jogging track Cleaned</th>\n",
       "      <th>Swimming Pool Cleaned</th>\n",
       "      <th>Gym Cleaned</th>\n",
       "      <th>Property Area in Sq. Ft. Cleaned</th>\n",
       "      <th>Price by sub-area</th>\n",
       "      <th>Amenities score</th>\n",
       "      <th>Price by Amenities score</th>\n",
       "      <th>Noun_Counts</th>\n",
       "      <th>Verb_Counts</th>\n",
       "      <th>Adjective_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country, Property Type Cleaned, Sub-Area Cleaned, Company Name Cleaned, TownShip Name/ Society Name Cleaned, Description Cleaned, ClubHouse Cleaned, School / University in Township Cleaned, Hospital in TownShip Cleaned, Mall in TownShip Cleaned, Park / Jogging track Cleaned, Swimming Pool Cleaned, Gym Cleaned, Property Area in Sq. Ft. Cleaned, Price by sub-area, Amenities score, Price by Amenities score, Noun_Counts, Verb_Counts, Adjective_Counts]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_preprocess.shape)\n",
    "df_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lib/model/count_vectorizer.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_features \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_preprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m, in \u001b[0;36mcreate_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_features\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Mở tệp chứa đối tượng CountVectorizer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlib/model/count_vectorizer.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         cv_object \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m     X \u001b[38;5;241m=\u001b[39m cv_object\u001b[38;5;241m.\u001b[39mtransform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription Cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32me:\\11Estate-Price\\modular_code\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lib/model/count_vectorizer.pkl'"
     ]
    }
   ],
   "source": [
    "df_features = create_features(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "760415f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # Mở tệp chứa đối tượng CountVectorizer\n",
    "    with open('lib/model/count_vectorizer.pkl', 'rb') as f:\n",
    "        cv_object = pickle.load(f)\n",
    "\n",
    "    X = cv_object.transform(df['Description Cleaned'])\n",
    "    df_ngram = pd.DataFrame(X.toarray(), columns=cv_object.get_feature_names_out())\n",
    "\n",
    "    # Thêm dữ liệu mới vào DataFrame gốc\n",
    "    df_final = pd.concat([df.reset_index(drop=True), df_ngram.reset_index(drop=True)], axis=1)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_features\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m df_features\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[43mdf_features\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m columns[:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "columns = df_features.columns.tolist()\n",
    "columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[43mdf_features\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Even if an integer of the type int64 is present in another object like a dictionary, \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#the TypeError exception will occur with the message “TypeError: Object of type int64 is not JSON serializable”\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "payload = df_features.iloc[3].to_dict()\n",
    "#Even if an integer of the type int64 is present in another object like a dictionary, \n",
    "#the TypeError exception will occur with the message “TypeError: Object of type int64 is not JSON serializable”\n",
    "import json\n",
    "# define a class to avoid that\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "payload = json.dumps(payload,cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'payload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpayload\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'payload' is not defined"
     ]
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = df_features.iloc[3].to_dict()\n",
    "payload = json.dumps(payload,cls=NpEncoder)\n",
    "\n",
    "out =  requests.post(url='https://property-price-prediction-live.herokuapp.com/predict',\n",
    "                data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"[85.55245708]\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(df_features)):\n",
    "    payload = df_features.iloc[i].to_dict()\n",
    "    payload = json.dumps(payload,cls=NpEncoder)\n",
    "    \n",
    "    out =  requests.post(url='https://property-price-prediction-live.herokuapp.com/predict',\n",
    "                    data=payload)\n",
    "    result = np.float(re.sub('[^A-Za-z0-9.]+', '', out.text))  \n",
    "    output.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.73696173,\n",
       " 57.70878214,\n",
       " 74.58849812,\n",
       " 85.55245708,\n",
       " 66.79123803,\n",
       " 84.59893199,\n",
       " 77.66213533,\n",
       " 108.16028495,\n",
       " 78.39072133,\n",
       " 109.57364513,\n",
       " 159.10621088,\n",
       " 176.79921586,\n",
       " 173.62768353,\n",
       " 82.30834029,\n",
       " 118.12537567,\n",
       " 50.24301879,\n",
       " 57.96254756,\n",
       " 79.05972822,\n",
       " 52.32957137,\n",
       " 69.86078406,\n",
       " 74.73422689,\n",
       " 103.96509677,\n",
       " 38.42625687,\n",
       " 62.09826553,\n",
       " 52.03298601,\n",
       " 56.40783384,\n",
       " 67.41405046,\n",
       " 88.43816135,\n",
       " 71.24488624,\n",
       " 73.88559514,\n",
       " 83.5413806,\n",
       " 84.88514865,\n",
       " 103.69906684,\n",
       " 102.73270284,\n",
       " 115.79059498,\n",
       " 61.73645075,\n",
       " 106.18832373,\n",
       " 85.2035976,\n",
       " 119.28481463,\n",
       " 42.50511413,\n",
       " 74.52375717,\n",
       " 143.78489959,\n",
       " 30.68352346,\n",
       " 37.17655204,\n",
       " 41.66563326,\n",
       " 84.43268267,\n",
       " 87.32860919,\n",
       " 115.21966742,\n",
       " 109.0564247,\n",
       " 123.23834368,\n",
       " 168.31854671,\n",
       " 42.84774364,\n",
       " 51.65022681,\n",
       " 55.37759299,\n",
       " 65.17603304,\n",
       " 60.00438345,\n",
       " 48.02535026,\n",
       " 58.46073342,\n",
       " 64.29291026,\n",
       " 56.84451424,\n",
       " 86.81352401,\n",
       " 42.71811613,\n",
       " 53.57938083,\n",
       " 71.38925869,\n",
       " 68.10531012,\n",
       " 89.62387405,\n",
       " 80.54255645,\n",
       " 198.02413568,\n",
       " 206.04585597,\n",
       " 71.86346632,\n",
       " 75.42780719,\n",
       " 68.29750563,\n",
       " 71.6028411,\n",
       " 101.65920588,\n",
       " 98.28978398,\n",
       " 49.31402349,\n",
       " 58.67832153,\n",
       " 65.44468952,\n",
       " 101.17783324,\n",
       " 70.94985793,\n",
       " 92.79167626,\n",
       " 100.56553118,\n",
       " 36.69869583,\n",
       " 41.03465445,\n",
       " 57.51660476,\n",
       " 129.13718503,\n",
       " 104.83352665,\n",
       " 56.81860231,\n",
       " 54.15596765,\n",
       " 54.0140884,\n",
       " 52.78332523,\n",
       " 54.99632164,\n",
       " 147.1047694,\n",
       " 151.06983648,\n",
       " 158.17612746,\n",
       " 171.80572794,\n",
       " 184.14667896,\n",
       " 185.42457951,\n",
       " 62.6327785,\n",
       " 80.45007225,\n",
       " 87.38493708,\n",
       " 88.82832672,\n",
       " 114.71905331,\n",
       " 118.52342566,\n",
       " 133.89414118,\n",
       " 127.78941741,\n",
       " 49.82525388,\n",
       " 53.14347139,\n",
       " 41.20612597,\n",
       " 49.22784625,\n",
       " 48.46613121,\n",
       " 46.9374395,\n",
       " 47.70178535,\n",
       " 66.77560635,\n",
       " 99.57873886,\n",
       " 99.76561911,\n",
       " 104.72261629,\n",
       " 132.78680943,\n",
       " 143.78560808,\n",
       " 68.63605051,\n",
       " 88.45795607,\n",
       " 78.32650261,\n",
       " 91.80755637,\n",
       " 73.25928293,\n",
       " 70.71176549,\n",
       " 75.16217959,\n",
       " 101.13640178,\n",
       " 125.79157006,\n",
       " 156.31923186,\n",
       " 71.43341516,\n",
       " 69.13488019,\n",
       " 167.61816787,\n",
       " 54.22598083,\n",
       " 56.35135397,\n",
       " 64.0215926,\n",
       " 95.02977235,\n",
       " 91.6406071,\n",
       " 103.22321155,\n",
       " 131.98194994,\n",
       " 127.53614369,\n",
       " 135.76576043,\n",
       " 55.67023468,\n",
       " 64.32300233,\n",
       " 67.35364023,\n",
       " 88.65141817,\n",
       " 114.40368235,\n",
       " 69.98262209,\n",
       " 72.63450426,\n",
       " 80.3732065,\n",
       " 61.07579212,\n",
       " 60.83163938,\n",
       " 50.25739822,\n",
       " 52.82766646,\n",
       " 78.02168578,\n",
       " 80.09280294,\n",
       " 41.21853188,\n",
       " 46.27259709,\n",
       " 62.4600622,\n",
       " 92.84558114,\n",
       " 98.57878141,\n",
       " 99.41249173,\n",
       " 46.16730005,\n",
       " 58.74478641,\n",
       " 44.42937561,\n",
       " 52.42470837,\n",
       " 77.68093174,\n",
       " 81.77121323,\n",
       " 187.80992054,\n",
       " 199.21588711,\n",
       " 58.85402194,\n",
       " 81.20990984,\n",
       " 69.98181477,\n",
       " 99.05021164,\n",
       " 63.77388586,\n",
       " 47.40959022,\n",
       " 43.85190372,\n",
       " 45.8836447,\n",
       " 44.48565898,\n",
       " 56.04043329,\n",
       " 64.54846529,\n",
       " 71.17383046,\n",
       " 70.0195556,\n",
       " 146.50860221,\n",
       " 180.87147588,\n",
       " 188.94860414,\n",
       " 42.68429272,\n",
       " 42.28738761,\n",
       " 44.07964764,\n",
       " 56.25191475,\n",
       " 52.36277989,\n",
       " 46.44201944,\n",
       " 28.66659645,\n",
       " 28.94623141,\n",
       " 95.36841668,\n",
       " 127.8689963,\n",
       " 148.92776178,\n",
       " 175.39909445,\n",
       " 93.18527057,\n",
       " 131.97620132,\n",
       " 100.7738478]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data= pd.read_excel(r'../data/Pune Real Estate Data.xlsx')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_interval(interval_estimate, prediction):\n",
    "    '''\n",
    "    Get a prediction interval for a linear regression model.\n",
    "    \n",
    "    INPUTS: \n",
    "        - interval_estimate based on the final model's performance on the training data \n",
    "        - predicted values for the test data,\n",
    "        - Prediction interval threshold (default = .95) \n",
    "    OUTPUT: \n",
    "        - Prediction interval for single test prediction\n",
    "    '''\n",
    "    \n",
    "    #generate prediction interval lower and upper bound cs_24\n",
    "    lower, upper = prediction - interval_estimate, prediction + interval_estimate\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(31.826834460432938)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "fileName = 'model/interval_est.pkl'\n",
    "with open(fileName,'rb') as f:\n",
    "    interval = pickle.load(f)\n",
    "\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m lower_vet \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m upper_vet \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m \u001b[43moutput\u001b[49m:\n\u001b[0;32m      6\u001b[0m     lower, upper \u001b[38;5;241m=\u001b[39m  get_prediction_interval(interval,out)\n\u001b[0;32m      7\u001b[0m     lower_vet\u001b[38;5;241m.\u001b[39mappend(lower)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# getting prediction intervals for the test data\n",
    "lower_vet = []\n",
    "upper_vet = []\n",
    "\n",
    "for out in output:\n",
    "    lower, upper =  get_prediction_interval(interval,out)\n",
    "    lower_vet.append(lower)\n",
    "    upper_vet.append(upper)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mzip\u001b[39m(lower_vet,upper_vet,\u001b[43moutput\u001b[49m),columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(zip(lower_vet,upper_vet,output),columns=['lower','upper','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
